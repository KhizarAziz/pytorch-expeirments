{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-Experiements.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "K-Vim8daMrvZ",
        "OaIuLGsWoFPE",
        "T5kysTKVrsiu",
        "3kNhlC7e1uaA",
        "wN58SXslr9ap",
        "ghSI6IM5sBqJ",
        "YN2W1UuZukzH",
        "BNsZR9N_ZrNp",
        "O8yove4cIZQr"
      ],
      "authorship_tag": "ABX9TyPCZhGNtq/FSrg/L4rv6mgQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhizarAziz/pytorch-expeirments/blob/main/Pytorch_Experiements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pgWwJFomiJ8"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "torch.manual_seed(0)\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import utils,transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPdDGY0lJOJ8"
      },
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-Vim8daMrvZ"
      },
      "source": [
        "# **Download Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOfE_B7sA1Jf"
      },
      "source": [
        "# download dataset\n",
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/oxford-102-flowers.tgz\n",
        "#extract\n",
        "!tar -xvf oxford-102-flowers.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaIuLGsWoFPE"
      },
      "source": [
        "# **Preprocess Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sLFy_2Emu0G"
      },
      "source": [
        "# Creating Custom Dataset from this class\n",
        "class FlowersDataset(Dataset):\n",
        "  def __init__(self,root_dir,data_csv,transform=None):\n",
        "    self.root_dir = root_dir\n",
        "\n",
        "    self.data_csv = pd.read_csv(data_csv,sep=\" \", header=None)\n",
        "    self.data_csv.columns = [\"imgPath\", \"id\"] \n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_csv)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    image_path = os.path.join(self.root_dir,self.data_csv.iloc[idx,0])\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img_class = self.data_csv.iloc[idx,1]\n",
        "    if self.transform:\n",
        "      tranformed_img = self.transform(img)\n",
        "    \n",
        "\n",
        "    single_row_dict_obj = {'image':tranformed_img,'class':img_class}\n",
        "    return single_row_dict_obj\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_WzQai97G5M"
      },
      "source": [
        "#defining transforms\n",
        "std = 0.5\n",
        "mean = 0.5\n",
        "tfms = transforms.Compose([transforms.ToTensor(),\n",
        "                           transforms.Resize((224,224)),\n",
        "                             transforms.Normalize(mean,std)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VWpft086l7W"
      },
      "source": [
        "dataset_dir = '/content/oxford-102-flowers/'\n",
        "#Training DataLoader\n",
        "meta_csv = '/content/oxford-102-flowers/train.txt'\n",
        "trainDataset = FlowersDataset(dataset_dir,meta_csv,tfms)\n",
        "trainLoader = DataLoader(trainDataset,batch_size=64,shuffle=True)\n",
        "\n",
        "# Validation DataLoader\n",
        "meta_csv = '/content/oxford-102-flowers/valid.txt'\n",
        "valDataset = FlowersDataset(dataset_dir,meta_csv,tfms)\n",
        "valLoader = DataLoader(valDataset,batch_size=64,shuffle=True)\n",
        "\n",
        "# Test DataLoader\n",
        "meta_csv = '/content/oxford-102-flowers/test.txt'\n",
        "testDataset = FlowersDataset(dataset_dir,meta_csv,tfms)\n",
        "testLoader = DataLoader(testDataset,batch_size=64,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5kysTKVrsiu"
      },
      "source": [
        "# **Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAQc41C0I5pJ"
      },
      "source": [
        "model = torchvision.models.resnet34(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kNhlC7e1uaA"
      },
      "source": [
        "# **Freeze Initial Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjb280NS1_iH"
      },
      "source": [
        "# freezing network\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "print(next(iter(model.layer4.parameters())).requires_grad)\n",
        "print(next(iter(model.fc.parameters())).requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN58SXslr9ap"
      },
      "source": [
        "# **Unfreeze Full Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_avdCAksAz4"
      },
      "source": [
        "# freezing network\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "print(next(iter(model.layer4.parameters())).requires_grad)\n",
        "print(next(iter(model.fc.parameters())).requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghSI6IM5sBqJ"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09S7v8I42z-4"
      },
      "source": [
        "#modifying top to spit out 102 categories -> as our dataset has 102 possible catergories\n",
        "model.fc = nn.Linear(in_features=512, out_features=102, bias=True)\n",
        "print(next(iter(model.layer4.parameters())).requires_grad)\n",
        "print(next(iter(model.fc.parameters())).requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0R2v1TDI8LX",
        "outputId": "10169d2c-f092-40db-89d3-f8ccea9bf327"
      },
      "source": [
        "print(next(iter(model.layer4.parameters())).requires_grad)\n",
        "print(next(iter(model.fc.parameters())).requires_grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS9HEqFf-F94"
      },
      "source": [
        "#loading to gpu\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL9yU9s0JJPx"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "lr = 0.02\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbP95nlx8DeX"
      },
      "source": [
        "accuracy_tracker = []"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohCSpThb7ebX"
      },
      "source": [
        "total_epochs = 10\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(total_epochs):\n",
        "  batch_loss = 0\n",
        "  for batch,sample_dict in enumerate(trainLoader):\n",
        "    images = sample_dict['image']\n",
        "    labels = sample_dict['class']\n",
        "    images =images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad() # reset gradients for new batch\n",
        "    output = model(images) # forward pass\n",
        "    loss = loss_func(output,labels) # calculate loss\n",
        "    loss.backward() #backward pass\n",
        "    optimizer.step() # update weights\n",
        "\n",
        "    batch_loss += loss.item() # update batch loss\n",
        "\n",
        "  print(f'Epoch: {epoch}/{total_epochs} - Training Loss: {batch_loss/len(trainLoader)} - ',end=' ')\n",
        "\n",
        "  with torch.no_grad(): # disable autograd\n",
        "    # Cross validation \n",
        "      test_loss = 0\n",
        "      correct_preds = 0\n",
        "      total_items = 0\n",
        "\n",
        "      for batch,val_sample in enumerate(valLoader,1):\n",
        "          images = val_sample['image']\n",
        "          labels = val_sample['class']\n",
        "          images = images.to(device) # loading to 'gpu' or 'cpu'\n",
        "          labels = labels.to(device) ## loading to 'gpu' or 'cpu'\n",
        "\n",
        "          # forward pass\n",
        "          output_withLog = model(images)\n",
        "\n",
        "          #loss\n",
        "          batch_loss = loss_func(output_withLog,labels)\n",
        "          test_loss += batch_loss.item()\n",
        "\n",
        "          #check prediction\n",
        "          output = torch.exp(output_withLog)\n",
        "          pred = torch.argmax(output,1)\n",
        "          total_items += labels.size(0)\n",
        "          correct_preds += (pred == labels).sum().item()\n",
        "\n",
        "      accuracy_tracker.append(correct_preds/total_items)\n",
        "      print(f\"Accuracy: {correct_preds/total_items}\",end='\\n')\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "time_elapsed = end_time-start_time\n",
        "\n",
        "print(f\"Total_Epochs: {total_epochs}  - Accuracy: {correct_preds*100/total_items}%\")\n",
        "print(f'took {time_elapsed} seconds to train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urYzG7f24Iyy",
        "outputId": "fc340d85-be05-4214-cac3-d1d39b51cb2d"
      },
      "source": [
        "len(accuracy_tracker)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN2W1UuZukzH"
      },
      "source": [
        "# **My Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMsRGQMjrY1o"
      },
      "source": [
        "# 30 epochs on full Model (All layers unfrozen)\n",
        "  # Accuracy = 15.58% :   Time: 559.05 Seconds\n",
        "%matplotlib inline\n",
        "plt.plot(accuracy_tracker,label=\"Accuracy\")\n",
        "plt.legend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b6n79hmuY7W"
      },
      "source": [
        "# Initial Layers frozen for 10 epochs, Unfrozen All model for 20 epochs\n",
        "%matplotlib inline\n",
        "plt.plot(accuracy_tracker,label=\"Accuracy\")\n",
        "plt.legend  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0jPSYVM1QiPJ",
        "outputId": "b5d5ae86-2e2e-4803-8aa9-d4d4e916fdd0"
      },
      "source": [
        "# Initial Layers frozen for 10 epochs, Unfrozen 10 for epochs\n",
        "  # Accuracy = 76.76% :   Time:   96 Sec\n",
        "%matplotlib inline\n",
        "plt.plot(accuracy_tracker,label=\"Accuracy\")\n",
        "plt.legend  "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.legend>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcdb3/8dcna5tkuqRJJ93ShDaT0o0tFBAXREE2KSoquCBwlZ8/wZ9elCu44L1F/bld1HvleuUqCPzQilW0QqUuICgWaCkCXUiaLunepFuafZvP749MS6gpnbaTnFnez8ejj86c+Xbmw0DenJ7zOZ9j7o6IiKS+rKALEBGRxFCgi4ikCQW6iEiaUKCLiKQJBbqISJrICeqDS0pKvKKiIqiPFxFJSc8///xudy8d7LXAAr2iooIVK1YE9fEiIinJzBqO9JoOuYiIpAkFuohImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIuIpAkFukgaikadJ+ua+MOaXUGXIsMosAuLRCTxDnT2sGjFVh54poGNu9vIyTJWL3gH+TnZQZcmw0CBLpIGane2cP+yTTz8wjbau/s4Y+pYzqosZuHyLWzc3caMslFBlyjDQIEukqJ6+6L8Yc0u7lu2iWc27CUvJ4v5p0zkI2+oYPak0byy8wALl2+hdmeLAj1DKNBFUszu1i4WPreZB5/dzI7mTiaNGcmtF8/g/TVTGFuYd2jdSSVF5GQZdbtaAqxWhpMCXSRFvLB5H/cva+DRl3bQ3RflTVUlLJg/m/NnjCc7y/5hfV5OFpUlhdTubA2gWgmCAl0kiXX29PHISzu4f9kmXtraTFF+Dh84q5wPnT2V6eOLjvrnI+EQq7Y3D32hkhQU6CJJaNv+Dh58poGFy7ewt62b6eOLuGP+LN51+mSK8uP/sY2EQyxZtYP27l4K8vTjnu70b1gkSbg7y9bv4b5lmw71j18wM8xHzqngnGnjMPvHwypHU11WhDvUN7Yyd/KYBFcsySauQDezi4DvAdnAj9z964e9/h3grbGnBcB4d9d/PSJxaO3q5eGVW7lvWQP1ja0UF+bx8bdM44NnT2XSmJEn9N6RcAjob2tUoKe/owa6mWUDdwEXAFuB5Wa22N3XHFzj7v88YP0ngdOGoFaRtLK+qZUHljWw6PmttHb1MmfSaL793lO4bO4ERuQm5kKgqeMKycvJUqdLhohnD30eUO/uGwDMbCEwH1hzhPVXA19OTHki6aUv6jz+SiP3L9vEX9btJi87i0vnTuCac6Zy6pQxx3VY5fVkZxnTS4uo26VOl0wQT6BPArYMeL4VOGuwhWY2FagEHj/C6zcANwCUl5cfU6EiqWxfWzc/X7GFB5Y1sG1/B2WjRvDZCyO8/8xySkP5Q/rZ1WUhntmwZ0g/Q5JDok+KXgUscve+wV5097uBuwFqamo8wZ8tknRWbWvmvr9tYvGL2+nqjXL2ScV88dKTuWBmmJzs4ZmNFwmHePiFbTR39DB6ZO6wfKYEI55A3wZMGfB8cmzbYK4CbjzRokRSUWdPH80dPexr7+aVHS088EwDzzfsY2RuNleeMZlrzqmguiw07HVVl/X3q6/b1UJNRfGwf74Mn3gCfTlQZWaV9Af5VcAHDl9kZjOAscCyhFYoMsy6evvY394T+9XNvvYemju62d/ec9jj/t8PhnhnT/Q171NZUsjtl83kPWdMDnTP+FCniwI97R010N2918xuApbS37Z4j7uvNrMFwAp3XxxbehWw0N11KEWSQldvH83tPezv6GFfWzf7O3poPhjEHa8G9v7YmoOPO3oGPWIIQG62MXpkHmMLchlTkMvksQXMmdT/eExBXv/vI/MoG53PaVPGkjXIJfnDbdKYkRTmZbNOJ0bTXlzH0N19CbDksG23H/b8XxNXlsixaevq5Vcrt/LLldtoPNDJ/o4e2ruPHMw5WTYggHOZNGYksyaOYszIXMYW5jF6ZH9Ijy147eOCvOyEd6IMNTOjKhyidqdaF9OdrhSVlLZtfwf3/20TP3tuMwc6e5k9aRTnTCuJBXAuowvy+kP6YHjH9qQLUzCYT0R1OMQf1+ruRelOgS4px91ZuXk/9zy9kcdW7cTduXj2BK5/YyWnlye+lzsdRMpC/HzFFna3dlFSNLRtkhIcBbqkjJ6+KEte3sE9T2/ixS37GTUih4++sZIPnzOVyWMLgi4vqUXC/Z0udbtaFOhpTIEuSW9fWzc/fW4zDyxrYOeBTk4qKeSO+bN49+mTKTyGyYOZrDrW6VK3s4U3TCsJuBoZKvppkKS1blcL9zy9iYdf2EpnT/8NHf7vu+fwlkhpUnSPpJLSUD5jCnKpVadLWlOgS1KJRp2n1jVxz9ObeKquibycLN592iSuO7cykIty0oWZEQmHNKQrzSnQJSm0d/fyq5XbuPfpjaxvamN8KJ/PXhjh6nnljNMx34SoDof49QvbcHedOE5TCnQJ1Pb9Hdy/rIGfPbeZ5o4e5kwazXfffyqXzJlAXs7wzDrJFJFwES1dvew80MmE0Sc2Z12SkwJdAvHC5n38+K8b+V2s7fCi2WVcf24lZ0wdq73HITLwZhcK9PSkQJdh09MX5bFVO7nn6Y28sHk/ofwcrj+3gmvOqWBKsdoOh9rBQK/b1cJ51eMDrkaGggJdhtz+9m5+9twW7l+2iR3NnVSMK+DfLp/Fe844thsey4kZW5jH+FA+tTvV6ZKu9NMkQ6a+sZV7n97IL1f2tx2+Ydo4vnLFbN5aPV5thwGpLlOnSzpToEtCuTt/WbebH/91I0/G2g6vOHUi151byckTRgVdXsarGh/ip881EI26/qeahhTokhAd3X08/EJ/2+G6xlZKivK5+YIIHzirXJeaJ5HqsiI6e6Js2dfO1HGFQZcjCaZAlxP2u5d38KXfrGZ3axezJo7izvedwqVzJ5Cfk5g710viDOx0UaCnHwW6HLfdrV18+TerefTlHcyeNIrvf+A0zqosVtthEqsa0Oly4ayygKuRRFOgyzFzdx55aQdfXrya1s5ebnlHNTe8+SRyh+mmx3L8ivJzmDx2pGa6pCkFuhyTxpZOvvTrVSxdvYtTpozhW1fOPfTXeEkNkXCIdep0SUtx7VKZ2UVmVmtm9WZ26xHWvM/M1pjZajP7aWLLlKC5O79+YRsXfucpnqht4taLZ/DLj5+jME9BkXCI9U2t9PRFj75YUspR99DNLBu4C7gA2AosN7PF7r5mwJoq4DbgXHffZ2a6DC2N7DrQyRcefpk/rm3k9PIxfPPKU5g+vijosuQ4VZcV0dPnbNrdduiYuqSHeA65zAPq3X0DgJktBOYDawas+Rhwl7vvA3D3xkQXKsPP3Vn0/FbueGQN3X1RvnjpyVx3biXZ6l9OaYc6XXa1KNDTTDyBPgnYMuD5VuCsw9ZEAMzsaSAb+Fd3f+zwNzKzG4AbAMrLy4+nXhkm2/d38PmHX+bPtU3MqyjmG1fOpbJEbW7pYFppEVnWf/ci5gZdjSRSok6K5gBVwHnAZOApM5vj7vsHLnL3u4G7AWpqajxBny0J5O4sXL6Frz26lt6o86/vnMk151ToqsI0MiI3m4pxhdSp0yXtxBPo24ApA55Pjm0baCvwrLv3ABvNrI7+gF+ekCplWGzd185tv3qZv6zbzTknjeMb75lL+ThNQUxHuntReoqny2U5UGVmlWaWB1wFLD5sza/p3zvHzEroPwSzIYF1yhCKRp0HnmngHd95ipUN+/jKFbN58KNnKczTWKQsxKY9bXT29AVdiiTQUffQ3b3XzG4CltJ/fPwed19tZguAFe6+OPbahWa2BugDbnH3PUNZuCTG5j3tfO6XL7Fswx7eOL2Er79nDpPHKsjTXXU4RNT7J2LOnjQ66HIkQeI6hu7uS4Alh227fcBjB26O/ZIUEI069y/bxDceqyUny/j6u+fw/jOn6LL9DFFd1t92WrerRYGeRnSlaAbauLuNzy16iec27eW86lK+9q45TByjW5JlkqnjCsnNNp0YTTMK9AzSF3XufXoj31paS15OFt+6ci5XnjFZe+UZKDc7i2mlRToxmmYU6BmivrGVf1n0Iis37+ftJ4/nq++aQ3jUiKDLkgBFwiGeb9gXdBmSQAr0NNfbF+VHf93InX+ooyAvm+++/1TmnzpRe+VCdVmIxS9up6Wzh9CI3KDLkQRQoKexul0t3PKLF3lxazPvmBXmjitmMz6kvXLpd3AEwLrGVk4vHxtwNZIICvQ01NMX5YdPruc//lRP0Ygc/vPq07hs7gTtlctrRML9nS7rdrUo0NOEAj3NrN1xgFsWvciqbQe4dO4EFlw+i3G6p6cMYsrYAkbkZlG7U50u6UKBnia6e6P815/r+f7j9YwpyOUHHzydi+dMCLosSWJZWaYRAGlGgZ4GVm1r5rO/eJFXdrYw/9SJfPmdsyguzAu6LEkBkXCIJ+uagi5DEkSBnuJ+8Of1fPv3tRQX5nH3h8/QjX/lmFSHQyx6fiv72roZq52AlKe7+qawB55p4BuPvcJFs8r4wz+/WWEux6wq/OoIAEl9CvQU9cQrjXz5N6s4f8Z4vnfVqYwp0N6VHLvqsv7WRQV6elCgp6BV25q58acrOXnCKP7z6tPIyda/Rjk+ZaNGEBqRQ60CPS0oCVLM9v0d/NN9yxkzMpd7rj2TwnydBpHjZ2ZUh0PUqXUxLSjQU0hLZw/X/2Q5bV193HPdmZrFIgkRKQtRu6uF/inYksoU6Cmipy/KJx5cSX1jKz/40OnMKBsVdEmSJiLji2ju6KGppSvoUuQEKdBTgLvzpV+v4i/rdvPVd83mTVWlQZckaSQSOzGq4+ipT4GeAn7w5HoWLt/CjW+dxvvPLA+6HEkz1bEhXbU7FeipToGe5Ba/uJ1vPlbL5adM5DMXVAddjqShcUX5lBTlqXUxDcQV6GZ2kZnVmlm9md06yOvXmlmTmf099uujiS818yzftJfPPvQi8yqK+dZ755KVpWmJMjQi4RC1uh1dyjtqoJtZNnAXcDEwE7jazGYOsvTn7n5q7NePElxnxtm4u42P3b+CyWNH8sMPn0F+TnbQJUkai4RD1O9qIRpVp0sqi2cPfR5Q7+4b3L0bWAjMH9qyMtue1i6uvfc5ssy497ozNWNDhlwkHKKtu49t+zuCLkVOQDyBPgnYMuD51ti2w73HzF4ys0VmNmWwNzKzG8xshZmtaGrShLfBdPb0ccMDz7OjuZP/uaaGqeMKgy5JMkB1mWa6pINEnRT9LVDh7nOBPwD3DbbI3e929xp3ryktVevd4aJR5zO/eJHnG/bx3fefyhlTdRcZGR5VYbUupoN4An0bMHCPe3Js2yHuvsfdD16V8CPgjMSUl1m+ubSWR1/awW0Xz+AS3ZxChtGoEblMHD2COrUuprR4An05UGVmlWaWB1wFLB64wMwGps/lwNrElZgZHny2gf9+cj0fPKucG958UtDlSAaqCoeoU6dLSjvqZCd37zWzm4ClQDZwj7uvNrMFwAp3Xwz8HzO7HOgF9gLXDmHNaefPtY3c/pvVnFddyr9dPks3c5ZAVJeFWLZhD719UU3wTFFxjepz9yXAksO23T7g8W3AbYktLTOs2X6AGx9cSXU4xPc/cLp+kCQwkXCI7t4oDXvbmVZaFHQ5chyUHgHa0dzB9T9ZTmhE/yjcIo3ClQAdHAGg4+ipS4EekNauXq7/yQpau3q597ozKRutUbgSrOnjizBTp0sq0y5hAHr7otz44ErqdrVwz7VncvIEjcKV4I3My6a8uIB1OjGasrSHPszcnS/9ZjVP1jXxlStm85aI+vElefTPdNEeeqpSoA+zHz61gZ89t5n/fd40rp6nUbiSXKrDITbubqOrty/oUuQ4KNCH0SMvbefrv3uFy+ZO4JYLNQpXkk+kLERf1NnQ1BZ0KXIcFOjD5PmGvdz80IvUTB3Lt997ikbhSlI61Omiwy4pSYE+DDbtbuOj961g4ugR3H1NDSNyNQpXklNlSSE5WaZAT1EK9CG2r62b636yHIB7r5tHsUbhShLLy8misqSQ2p3qdElFCvQh1D8KdwXb9nfwP9fUUFmiUbiS/CJlIe2hpygF+hCJRp1bFr3E8k37uPN9p1BTURx0SSJxqQ6H2Ly3nfbu3qBLkWOkQB8i3/59Lb99cTufu2gGl82dGHQ5InGLxE6M1jfqsEuqUaAPgZ89t5n/+vN6rp5XzsffolG4kloi4f7BXLWa6ZJyFOgJ9lRdE1/89SreEinljvkahSupZ+q4QvJysnQcPQUp0BNo7Y4DfOLBlVSNL+L7HzhNo3AlJWVnGVXji6jVTJeUo8RJkF0HOrn+J8spzM/m3uvOJDQiN+iSRI5bdTikMbopSIGeAK1dvVx373IOdPRwz7VnMmH0yKBLEjkhkbIQOw900tzRE3QpcgwU6Ceoty/KJ3+6ktpdLXz/g6cza+LooEsSOWEHT4yu03H0lBJXoJvZRWZWa2b1Znbr66x7j5m5mdUkrsTk5e58efFqnqhtYsH8Wby1enzQJYkkxMHWRY3STS1HDXQzywbuAi4GZgJXm9nMQdaFgE8Bzya6yGT1P3/ZwIPPbuZ/veUkPnjW1KDLEUmYSWNGUpiXrePoKSaePfR5QL27b3D3bmAhMH+QdXcA3wA6E1hf0lq6eidfW/IKl86ZwOfeMSPockQSysyIlOlmF6kmnkCfBGwZ8HxrbNshZnY6MMXdH329NzKzG8xshZmtaGpqOuZik0VrVy9feHgVcyaN5t/fp1G4kp6qwyHdji7FnPBJUTPLAu4EPnO0te5+t7vXuHtNaWnq3nrtrifq2d3axVeumK1RuJK2qsIh9rR1s7u1K+hSJE7xBPo2YMqA55Nj2w4KAbOBP5vZJuBsYHG6nhjdvKedH/9lI+8+fRKnTBkTdDkiQ+bQzS50HD1lxBPoy4EqM6s0szzgKmDxwRfdvdndS9y9wt0rgGeAy919xZBUHLCvLVlLdpbxLzpuLmkuUhab6aLj6CnjqIHu7r3ATcBSYC3wkLuvNrMFZnb5UBeYTJat38Njq3fyifOmUTZ6RNDliAyp0qJ8xhbkaqZLCsmJZ5G7LwGWHLbt9iOsPe/Ey0o+fVFnwSNrmDRmJB97syYoSvozMyLhEHU6MZoydKVonB5asYW1Ow5w2yUzdCJUMkYkNtPF3YMuReKgQI/Dgc4evr20ljMrxnLpnAlBlyMybCJlIVq6etnRnBGXl6Q8BXocvv94PXvbu7n9Ms03l8xSrREAKUWBfhQbd7dx79MbufL0ycyZrMFbklkODulS62JqUKAfxdeWrCUvO4tbLqoOuhSRYTemII/wqHydGE0RCvTX8XT9bv6wZhc3nj+d8SG1KUpm6u900R56KlCgH0FvX5QFv13DlOKRXH9uZdDliAQmEg6xrrGFvqg6XZKdAv0IfrZ8C7W7Wvj8xSerTVEyWnU4RGdPlC1724MuRY5CgT6I5o4e7vx9LWdVFnPR7LKgyxEJVKRMnS6pQoE+iP/40zr2d/Rw+ztnqk1RMl7VeN2OLlUo0A+zvqmV+/62iavOnKL7g4oAhfk5TB47klp1uiQ9BfphvvroWkbkZnPzBWpTFDmoOjYCQJKbAn2AJ+uaePyVRj55/nRKQ/lBlyOSNCJlIdY3tdLdGw26FHkdCvSY3r4odzyyhqnjCrj23IqgyxFJKtXhEL1RZ9OetqBLkdehQI958NnN1De28oVLTiY/R22KIgNFDt69SCdGk5oCHdjf3s13/ljHudPHccHMcNDliCSdk0oLyTLNdEl2CnTgu39cx4GOHr50mdoURQYzIjebipJC9aInuYwP9HW7WnjgmQaunlfOjLJRQZcjkrSqdfeipJfxgf6VR9dSkJfNzRdEgi5FJKlFwiE27Wmjs6cv6FLkCOIKdDO7yMxqzazezG4d5PWPm9nLZvZ3M/urmc1MfKmJ98QrjTxZ18Sn3lbFuCK1KYq8nuqyEO5Q36i99GR11EA3s2zgLuBiYCZw9SCB/VN3n+PupwLfBO5MeKUJ1tMX5Y5H13BSSSHXnFMRdDkiSe/QzS50HD1pxbOHPg+od/cN7t4NLATmD1zg7gcGPC0Ekn7O5v3LGtjQ1MYXLj2ZvJyMP/IkclRTxxWSl52lE6NJLCeONZOALQOebwXOOnyRmd0I3AzkAecP9kZmdgNwA0B5efmx1powe9u6+d4f63hTVQnnzxgfWB0iqSQ3O4uTSgvVupjEErZr6u53ufs04HPAF4+w5m53r3H3mtLS0kR99DH7zh/qaOvu43a1KYock+oydboks3gCfRswZcDzybFtR7IQuOJEihpKtTtbePDZBj50VjlVsavfRCQ+kXCIbfs7aOnsCboUGUQ8gb4cqDKzSjPLA64CFg9cYGZVA55eCqxLXImJ4+7c8cgaQiNy+fTb1aYocqwOjgBYp06XpHTUQHf3XuAmYCmwFnjI3Veb2QIzuzy27CYzW21mf6f/OPpHhqziE/DHtY38tX43n357FWML84IuRyTlVB+c6aLj6EkpnpOiuPsSYMlh224f8PhTCa4r4bp6+/jqo2uYPr6ID509NehyRFLS5LEjGZmbrU6XJJUx/Xr3/62BTXva+eKlJ5ObnTH/2CIJlZVlRMJF6kVPUhmRbLtbu/iPP63jrdWlnFetNkWRExHRTJeklRGB/u+/r6Ojp48vXJoSEwlEklokHKKppYu9bd1BlyKHSftAX7P9AD9fvpkPnzOV6bG7l4vI8YuU6WYXySqtA93dWfDIakaPzOXTb1ObokgiVOvuRUkrrQN96epdPLNhLzdfEGF0QW7Q5YikhfCofEaNyFGgJ6G0DfSu3j6+tmQtkXARV88Lbm6MSLoxs/4RADt1YjTZpG2g3/PXTWze286XLptJjtoURRKqKhyidlcL7kk/WDWjpGXSNbZ08v3H1/H2k8fzpqrghoCJpKvqcIjmjh4aW7qCLkUGSMtA//eldXT3RdWmKDJEDs50qdUIgKSSdoG+alszDz2/hWvfUEFlSWHQ5YikJd29KDmlVaC7Owt+u4bigjw++baqo/8BETku44ryKSnKV6AnmbQK9CUv7+S5TXu5+cIIo0aoTVFkKEXCRdRqBEBSSZtA7+zpb1OcURbiqjPVpigy1CLhEOt2tRCNqtMlWaRNoP/4rxvZtr+D2985k+ws3VZOZKhVl4Vo7+5j2/6OoEuRmLQI9F0HOrnriXreMSvMG6aVBF2OSEaIaARA0kmLQP/mY7X09jmfv+TkoEsRyRgHO110s4vkkfKB/uKW/fxy5Vaue2MFU8epTVFkuIRG5DJx9Ajdji6JxBXoZnaRmdWaWb2Z3TrI6zeb2Roze8nM/mRmw3KPt/5pimsoKcrnprdOH46PFJEBImUhdbokkaMGupllA3cBFwMzgavN7PBLMF8Aatx9LrAI+GaiCx3Mb1/awfMN+7jlHRFCalMUGXbV4RDrG1vp7YsGXYoQ3x76PKDe3Te4ezewEJg/cIG7P+Hu7bGnzwCTE1vmP+ro7uPrS9Yya+IorjxjylB/nIgMIhIO0d0XpWFv+9EXy5CLJ9AnAVsGPN8a23Yk/wT8brAXzOwGM1thZiuamprir3IQdz+1ge3Nndx+mdoURYJyqNNFx9GTQkJPiprZh4Aa4FuDve7ud7t7jbvXlJYe/xTEHc0d/PeT67lkThlnnTTuuN9HRE7M9PFFmKnTJVnkxLFmGzDwmMbk2LbXMLO3A18A3uLuQzpT8xu/e4U+d267WG2KIkEamZfN1OIC9aIniXj20JcDVWZWaWZ5wFXA4oELzOw04IfA5e7emPgyX7Vy8z5+/fftfOxNlUwpLhjKjxKROETCIY3RTRJHDXR37wVuApYCa4GH3H21mS0ws8tjy74FFAG/MLO/m9niI7zdCVuz/QCTx47kE+epTVEkGVSXhdi0p52u3r6gS8l48Rxywd2XAEsO23b7gMdvT3BdR/Shs6dy5RmTGZGbPVwfKSKvoyocoi/qbGhq4+QJo4IuJ6Ol5JWiCnOR5FGtmS5JIyUDXUSSR2VJITlZpuPoSUCBLiInJC8ni5NKC7WHngQU6CJywiLhEHWa6RI4BbqInLBIOMTmve20d/cGXUpGU6CLyAk7OAJgnfbSA6VAF5ETVl3WH+gaARAsBbqInLDy4gLyc7I0pCtgCnQROWHZWUZVuIi6Rh1yCZICXUQSIjI+pD30gCnQRSQhImUhdh7opLm9J+hSMpYCXUQS4tAIgEbtpQdFgS4iCRE52Omiwy6BUaCLSEJMHD2Covwc1ql1MTAKdBFJCLP+Thf1ogdHgS4iCVMdu3uRuwddSkZSoItIwkTCIfa197C7tTvoUjKSAl1EEubgCACN0g2GAl1EEiaiuxcFKq5AN7OLzKzWzOrN7NZBXn+zma00s14zuzLxZYpIKigpymNsQa4CPSBHDXQzywbuAi4GZgJXm9nMw5ZtBq4FfproAkUkdZgZkdiJURl+8eyhzwPq3X2Du3cDC4H5Axe4+yZ3fwmIDkGNIpJCqsv6716kTpfhF0+gTwK2DHi+NbbtmJnZDWa2wsxWNDU1Hc9biEiSi4RDtHb1sr25M+hSMs6wnhR197vdvcbda0pLS4fzo0VkmKjTJTjxBPo2YMqA55Nj20RE/kFkfCzQdRx92MUT6MuBKjOrNLM84Cpg8dCWJSKpanRBLuFR+RoBEICjBrq79wI3AUuBtcBD7r7azBaY2eUAZnammW0F3gv80MxWD2XRIpLcIuGQDrkEICeeRe6+BFhy2LbbBzxeTv+hGBERqsMhHnimgb6ok51lQZeTMXSlqIgkXKQsRFdvlC1724MuJaMo0EUk4Q6OANBx9OGlQBeRhKsaXwSo02W4KdBFJOEK83OYUjxSe+jDTIEuIkOiOhxi3a7WoMvIKAp0ERkSkXCI9U2tdPdqxNNwUaCLyJCIhEP0Rp1Ne9qCLiVjKNBFZEgc6nTRidFho0AXkSFxUmkh2VmmK0aHkQJdRIbEiNxsKsYVKNCHUVyX/ouIHI/qshBrdwQX6NGo09jSRcOeNrbs66Cjpy+wWgY6q7L40CGpRFKgi8iQqRof4nerdtLZ08eI3Owh+YzOnj627jfOwFkAAAT/SURBVGtn8952Gvb0/9qyt52Gvf2/dyVhl81XrpitQBeR1FJdFsId6htbmT1p9HG9h7uzr70nFtht/WG959XA3nmgk4F3uyvIy6a8uICTSgp5a3Up5cUFlI8rpLy4gKL85Ii8oaojOf7pRCQtDex0eb1A7+2LsqO5k4Y9sT3tvW1sjj3evKedlq7e16wvDeUztbiAc6aNo7y4gKnjCigv7g/tkqI8zDJzwqMCXUSGTMW4AvKys6hrbKGtq/fQYZHNe9sGPG5n274OeqOv7mbnZhtTxhYwpbiAM6aO7d/LLi5g6rhCphSPpCBP0TUYfSsiMmRysrOYNr6IH/1lIz98csNrXhs9Mpfy4gJmTxrNpXMmxA6N9Af3hNEjNUf9OCjQRWRIffL86TxV18SUQ4dGCphaXMjogtygS0s7CnQRGVKXzJnAJXMmBF1GRojrwiIzu8jMas2s3sxuHeT1fDP7eez1Z82sItGFiojI6ztqoJtZNnAXcDEwE7jazGYetuyfgH3uPh34DvCNRBcqIiKvL5499HlAvbtvcPduYCEw/7A184H7Yo8XAW+zTO0bEhEJSDyBPgnYMuD51ti2Qde4ey/QDIw7/I3M7AYzW2FmK5qamo6vYhERGdSwDudy97vdvcbda0pLS4fzo0VE0l48gb4NmDLg+eTYtkHXmFkOMBrYk4gCRUQkPvEE+nKgyswqzSwPuApYfNiaxcBHYo+vBB53HzhdQUREhtpR+9DdvdfMbgKWAtnAPe6+2swWACvcfTHwY+ABM6sH9tIf+iIiMowsqB1pM2sCGo7zj5cAuxNYTqrT9/Fa+j5epe/itdLh+5jq7oOehAws0E+Ema1w95qg60gW+j5eS9/Hq/RdvFa6fx+6BZ2ISJpQoIuIpIlUDfS7gy4gyej7eC19H6/Sd/Faaf19pOQxdBER+UepuocuIiKHUaCLiKSJlAv0o81mzxRmNsXMnjCzNWa22sw+FXRNycDMss3sBTN7JOhagmZmY8xskZm9YmZrzeycoGsKipn9c+znZJWZ/czMRgRd01BIqUCPczZ7pugFPuPuM4GzgRsz+LsY6FPA2qCLSBLfAx5z9xnAKWTo92Jmk4D/A9S4+2z6r3hPy6vZUyrQiW82e0Zw9x3uvjL2uIX+H9bDxxpnFDObDFwK/CjoWoJmZqOBN9M/lgN373b3/cFWFagcYGRseGABsD3geoZEqgV6PLPZM07sln+nAc8GW0ngvgv8CxANupAkUAk0AffGDkH9yMwKgy4qCO6+Dfg2sBnYATS7+++DrWpopFqgy2HMrAj4JfBpdz8QdD1BMbPLgEZ3fz7oWpJEDnA68AN3Pw1oAzLynJOZjaX/b/KVwESg0Mw+FGxVQyPVAj2e2ewZw8xy6Q/zB939V0HXE7BzgcvNbBP9h+LON7P/F2xJgdoKbHX3g39rW0R/wGeitwMb3b3J3XuAXwFvCLimIZFqgR7PbPaMELtn64+Bte5+Z9D1BM3db3P3ye5eQf9/F4+7e1ruhcXD3XcCW8ysOrbpbcCaAEsK0mbgbDMriP3cvI00PUF81HnoyeRIs9kDLiso5wIfBl42s7/Htn3e3ZcEWJMkl08CD8Z2fjYA1wVcTyDc/VkzWwSspL877AXSdASALv0XEUkTqXbIRUREjkCBLiKSJhToIiJpQoEuIpImFOgiImlCgS4ikiYU6CIiaeL/A9ofQ1yxh1OyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNsZR9N_ZrNp"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzqFcSNJ9yI7"
      },
      "source": [
        "model.to('cpu')\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  sample = next(iter(testLoader))\n",
        "  testImages = sample['image']\n",
        "  testLabels = sample['class']\n",
        "  output_withLog = model(testImages)\n",
        "  output = torch.exp(output_withLog) #anti log\n",
        "  pred = torch.argmax(output,1) # get highest probablity class (%)\n",
        "\n",
        "  print(f\"First output probability distribution {output[0]}, highest probablity calss {pred[0]} from distribution & total predictions {len(pred)}\")\n",
        "model = model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGYMscVXe1F6"
      },
      "source": [
        "# display image with class\n",
        "\n",
        "def denormalize(tensor):\n",
        "  return tensor*std + mean\n",
        "\n",
        "def show_img(img):\n",
        "  img = img.numpy().transpose((1,2,0)) # converting tensor(3,224,224) to (224,224,3)\n",
        "  # print(img.shape,type(img))\n",
        "  img = denormalize(img)\n",
        "  img = np.clip(img,0,1)\n",
        "  plt.imshow(img)\n",
        "\n",
        "\n",
        "test_img_id = 6\n",
        "show_img(testImages[test_img_id])\n",
        "print(pred[test_img_id])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cco5vGRdC8B"
      },
      "source": [
        "pred == testLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8yove4cIZQr"
      },
      "source": [
        "# **Playground**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60Yd7lS8Kd8"
      },
      "source": [
        "plt.figure()\n",
        "for i in range(len(dataset)):\n",
        "    sample = dataset[i]\n",
        "\n",
        "    print(i, sample['image'].shape, sample['class'].shape)\n",
        "\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    x = sample['image'].numpy()# convert to numpy img\n",
        "    plt.imshow(x[1]) # just show 1 channel of image, because its in shape 3,224,224\n",
        "\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFzaEvipES8y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsJsbhB3AQNj"
      },
      "source": [
        "t = torch.tensor(4,4,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPHNxiOZ_hCu"
      },
      "source": [
        "t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtkhUdJM4U11"
      },
      "source": [
        "df = pd.read_csv('/content/oxford-102-flowers/train.txt',sep=\" \", header=None)\n",
        "df.columns = [\"imgPath\", \"id\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5dk9Lsj5EQY"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa0Fml3V49Qq"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdlUbU6EE1Et"
      },
      "source": [
        "#shape of batch\n",
        "batch_of_data = next(iter(trainLoader))\n",
        "batch_of_data['image'].shape,batch_of_data['class'].shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}